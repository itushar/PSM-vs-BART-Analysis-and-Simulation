---
title: "R Notebook"
author: "Tushar"
output: rmarkdown::github_document
---

## 1. Data Description

This analysis simulates hypothetical data where the treatment group consists of children who attend private schools. The question of interest here is the effect of attending private schools on their overall performance scores.

The data includes overall income of the family (income), Mother's age (momage), father's age (dadage), number of events attending by parents (events), number of siblings (siblings)

  
## 2. Data Generation Description

The response surface for World A is linear and all assumptions hold. The $Y(0)$ and $Y(1)$ are

$$
Y(0) = income + (0.5*momage) + (0.4*dadage) - (2*events) - (2*siblings) + \epsilon \\ 
Y(1) = 20 + income + (0.5*mo
mage) + (0.4*dadage) - (2*events) - (2*siblings) + \epsilon
$$
Atleast one of the respose surface in World B should be non linear (with R square less that 0.75) and other assumptions hold.

$$
Y(0) = income + (0.5*momage) + (0.4*dadage) - (2*events) - (2*siblings) + \epsilon \\ \\
Y(1) = (0.05*income^2) + (0.5*momage) + (0.4*dadage) - (0.1*events^2) -\\ (2*siblings) - (0.18*income/siblings) + \epsilon
$$

World C has the same response surface as World B but violates one of the assumptions

$$
Y(0) = income + (0.5*momage) + (0.4*dadage) - (2*events) - (2*siblings) + \epsilon \\ \\
Y(1) = (0.05*income^2) + (0.5*momage) + (0.4*dadage) - (0.1*events^2) -\\ (2*siblings) - (0.18*income/siblings) + \epsilon\
$$

## 3. Data Generation Process

```{r}
set.seed(123)
library(matrixcalc)
library(MASS)
library(arm)


# generate sample data
mu <- c(30, 30, 32, 3, 2)

#Cov matrix
sigma <- matrix(c(10, 0.6, 0.8, 0.1, 0.5, 0.6, 4,0.3, 0.3, 0.7, 0.8, 0.3, 4, 0.2, 0.8, 0.1, 0.3, 0.2, 1, 0.2, 0.5, 0.7, 0.8, 0.2, 1), 5, 5)

sigmat <- t(sigma)

Sigma <- sigma*sigmat
is.positive.definite(Sigma)

set.seed(1234)
d <- as.data.frame(mvrnorm(1000, mu, Sigma))
colnames(d) <- c("income", "momage", "dadage", "events", "siblings")

#print(min(d$income))
```


```{r}
income <- d$income
momage <- d$momage
dadage <- d$dadage
events <- d$events
siblings <- d$siblings
```


### 3a. World A

```{r}

y0_hat <- income + 0.5*momage + 0.4*dadage - 2*events + 2*siblings
y1_hat <- 20 + income + 0.5*momage + 0.4*dadage - 2*events + 2*siblings

#library(arm)
ps <- invlogit(2 + 0.22*income - 0.2*dadage - 0.2*momage + events + siblings)
#cat("Min : ",min(ps))
#cat("\nMax : ",max(ps))

#print(hist(z))
z <- rbinom(1000,1,ps)


y0 <- y0_hat + rnorm(1000,0,1)
y1 <- y1_hat + rnorm(1000,0,1)
y <- (y1*z) + (y0*(1-z))

worldA <- data.frame(income=income, momage=momage, dadage=dadage, events=events, siblings=siblings, y0=y0, y1=y1, y=y, z=z, ps=ps)

#print(max(y0_hat))
a.ate <- mean(worldA$y1 - worldA$y0)
a.ate <- round(a.ate, digits = 2)
cat("ATE for A - ", a.ate)
a.att <- mean(worldA$y1[worldA$z==1] - worldA$y0[worldA$z==1])
a.att <- round(a.att, digits = 2)
cat("\nATT for A - ", a.att)
#print(mean(worldA$income[z==0]))

```

### 3b. World B

```{r}

#y0_hat <- 0.2*income + momage + 10*momedu - 2*momwork + 2*first
#y1_hat <- 0.0001*income*income*income + momage + 10*momedu - 15*momwork + 15*first

y0_hat <- income + 0.5*momage + 0.4*dadage - 2*events + 2*siblings
y1_hat <- 0.05*income*income + 0.5*momage + 0.4*dadage + 0.1*events*events + 2*siblings - (0.18*income)/siblings

#print(min(y1_hat))
#print(max(y1_hat))

y0 <- y0_hat + rnorm(1000,0,1)
y1 <- y1_hat + rnorm(1000,0,1)
y <- (y1*z) + (y0*(1-z))
#worldB <- data.frame(income=income, momage=momage, momedu=momedu, first=first, momwork=momwork, y0=y0, y1=y1, y=y, z=z)

worldB <- data.frame(income=income, momage=momage, dadage=dadage, events=events, siblings=siblings, y0=y0, y1=y1, y=y, z=z, ps=ps)

b.ate <- mean(worldB$y1 - worldB$y0)
b.ate <- round(b.ate, digits = 2)
cat("ATE for B - ", b.ate)
b.att <- mean(worldB$y1[worldB$z==1] - worldB$y0[worldB$z==1])
b.att <- round(b.att, digits = 2)
cat("\nATT for B - ", b.att)

```

```{r}
# To Check R square value (around 0.75 is good)
print(summary(lm(formula = y ~ income + momage + dadage + events + siblings + z, data =worldB)))
```

## 3c. World C

```{r}
x <- rnorm(1000,80,20)
psC <- invlogit(0.25*income + events + siblings  - x*0.1)

#psC <- invlogit(0.22*income + events + siblings - 10)
#cat("Min : ",min(psC))
#cat("\nMax : ",max(psC))

#hist(z)
zC <- rbinom(1000,1,psC)

y0_hat <- income + 0.5*momage + 0.4*dadage - 2*events + 2*siblings
y1_hat <- 0.05*income*income + 0.5*momage + 0.4*dadage + 0.1*events*events + 2*siblings - (0.18*income)/siblings

#print(min(y0_hat))

y0 <- y0_hat + rnorm(1000,0,1)
y1 <- y1_hat + rnorm(1000,0,1)
y <- (y1*zC) + (y0*(1-zC))
worldC <- data.frame(income=income, momage=momage, dadage=dadage, events=events, siblings=siblings, y0=y0, y1=y1, y=y, z=zC, ps=psC)

c.ate <- mean(worldC$y1 - worldC$y0)
c.ate <- round(c.ate, digits = 2)
cat("ATE for C - ", c.ate)
c.att <- mean(worldC$y1[worldC$z==1] - worldC$y0[worldC$z==1])
c.att <- round(c.att, digits = 2)
cat("\nATT for C - ", c.att)
```

```{r}
#Overlap - world C
hist(worldC$ps[worldC$z==1], border="red", xlim=c(0,1), ylim=c(0,250), xlab="Pscore", main="World C - Propensity Score (Before Matching)")
hist(worldC$ps[worldC$z==0], border="blue", add=T)
legend("topright",legend=c("Treated","Control"), col =c("red","blue"), lty=1, cex= 0.8)
```

For World A, Linearity holds and there is enough overlaps from the plot.

```{r}
plot(worldA$income[z==0], worldA$y[z==0], col="blue",xlab="Income",ylab="Y",ylim=c(0,120), xlim=c(-10,70),main="WORLD A - Income vs Observed Outcomes")
points(worldA$income[z==1], worldA$y[z==1],col="red")
legend("topleft",legend=c("Control","Treated"), col =c("blue","red"),lty=3, cex = 0.8)
```

```{r}
#Bias
bias.table <- data.frame()

lr.A = summary(lm(formula = y ~ income + momage + dadage + events + siblings + z, data =worldA))

est.A = lr.A$coefficients["z","Estimate"]
std.A = est.A/sd(worldA$y)
biasA <- a.ate/sd(worldA$y) - std.A

cat("Bias (World A) :", biasA)

bias.temp <- data.frame(World = "World A", Bias = biasA)
bias.table <- rbind(bias.table, bias.temp)
```

For World B, Linearity dosen't hold, Ignorability holds as all confounders are considered.

```{r}
plot(worldB$income[worldB$z==0], worldB$y[worldB$z==0], col="blue",xlab="Income",ylab="Y",ylim=c(0,250), xlim=c(-10,60),main="WORLD B - Income vs Observed Outcomes")
points(worldB$income[worldB$z==1], worldB$y[worldB$z==1],col="red")
legend("topleft",legend=c("Control","Treated"), col =c("blue","red"),lty=3, cex = 0.8)
```

```{r}
lr.B = summary(lm(formula = y ~ income + momage + dadage + events + siblings + z, data =worldB))

est.B = lr.B$coefficients["z","Estimate"]
std.B = est.B/sd(worldB$y)
biasB <- b.ate/sd(worldB$y) - std.B

cat("Bias (World B) :", biasB)

bias.temp <- data.frame(World = "World B", Bias = biasB)
bias.table <- rbind(bias.table, bias.temp)
```

For World C, Linearity dosen't hold. Ignorability is also not satisfied as all the confoudners are not considered.

```{r}
plot(worldC$income[worldC$z==0], worldC$y[worldC$z==0], col="blue",xlab="Income",ylab="Y",ylim=c(0,250), xlim=c(-10,70),main="WORLD C - Income vs Observed Outcomes")
points(worldC$income[worldC$z==1], worldC$y[worldC$z==1],col="red")
legend("topleft",legend=c("Control","Treated"), col =c("blue","red"),lty=3, cex = 0.8)
```

```{r}
lr.C = summary(lm(formula = y ~ income + momage + dadage + events + siblings + z, data =worldC))

est.C = lr.C$coefficients["z","Estimate"]
std.C = est.C/sd(worldC$y)
biasC <- c.ate/sd(worldC$y) - std.C

cat("Bias (World C) :", biasC)

bias.temp <- data.frame(World = "World C", Bias = biasC)
bias.table <- rbind(bias.table, bias.temp)
```

```{r}
print(bias.table)
```

## 4. Methods and Estimand

### 4.a Estimand

Here we are trying to estimate the effect of attending private schools on their overall performance scores. Hence we need the effect of the treatment on the treated or ATT.

### Method 1- Propensity score matching

#### World A

```{r}
library(MatchIt)
library(survey)

# Getting Weights
set.seed(1234)
matches.A <- matchit(z~ income + momage + dadage + events + siblings, data=worldA, method = "nearest", distance = "logit", caliper = 0.3)

#table(matches$weights)
matched.A <- numeric(nrow(worldA))
a <- 1
for(i in 1:nrow(worldA)){
  if(matches.A$weights[i]==1)
    matched.A[a] <- i
  a = a +1
}

worldA_m <- worldA[matched.A,]
table(worldA_m$z)

#LR with weights

result_psm <- data.frame()

lr_m_design_A <- svydesign(ids=~1, weights=~matched.A, data=worldA)
lr_m_A <- summary(svyglm(y~ z + income + momage + dadage + events + siblings, design=lr_m_design_A, data=worldA))

cala.att.psm <- lr_m_A$coefficients["z", "Estimate"]
cala.sd.psm <- lr_m_A$coefficients["z","Std. Error"]

temp.result <- data.frame(World = "World A", SATE=a.ate, SATT=a.att, ATT=cala.att.psm, sd=cala.sd.psm, Bias=biasA )

result_psm <- rbind(result_psm, temp.result)
print(lr_m_A)
```

#### World B

```{r}
matches.B <- matchit(z~ income + momage + dadage + events + siblings, data=worldB, method = "nearest", distance = "logit", caliper = 0.3)

#table(matches$weights)
matched.B <- numeric(nrow(worldB))
a <- 1
for(i in 1:nrow(worldB)){
  if(matches.B$weights[i]==1)
    matched.B[a] <- i
  a = a +1
}

worldB_m <- worldB[matched.B,]
table(worldB_m$z)

lr_m_design_B <- svydesign(ids=~1, weights=~matched.B, data=worldB)
lr_m_B <- summary(svyglm(y~ z + income + momage + dadage + events + siblings, design=lr_m_design_B, data=worldB))
calb.att.psm <- lr_m_B$coefficients["z", "Estimate"]
calb.sd.psm <- lr_m_B$coefficients["z","Std. Error"]

temp.result <- data.frame(World = "World B", SATE=b.ate, SATT=b.att, ATT=calb.att.psm, sd=calb.sd.psm, Bias=biasB )

result_psm <- rbind(result_psm, temp.result)
print(lr_m_B)
```

#### World C

```{r}
matches.C <- matchit(z~ income + momage + dadage + events + siblings, data=worldB, method = "nearest", distance = "logit", caliper = 0.3)

#table(matches$weights)
matched.C <- numeric(nrow(worldC))
a <- 1
for(i in 1:nrow(worldB)){
  if(matches.C$weights[i]==1)
    matched.C[a] <- i
  a = a +1
}

worldC_m <- worldC[matched.C,]
table(worldC_m$z)

lr_m_design_C <- svydesign(ids=~1, weights=~matched.C, data=worldC)
lr_m_C <- summary(svyglm(y~ z + income + momage + dadage + events + siblings, design=lr_m_design_C, data=worldC))

calc.att.psm <- lr_m_C$coefficients["z", "Estimate"]
calc.sd.psm <- lr_m_C$coefficients["z","Std. Error"]

temp.result <- data.frame(World = "World C", SATE=c.ate, SATT=c.att, ATT=calc.att.psm, sd=calc.sd.psm, Bias=biasC )

result_psm <- rbind(result_psm, temp.result)

print(lr_m_C)
```


### Method 2- BART

```{r}
library(devtools)
#library(devtools)
install_github("vdorie/bartCause")
library(bartCause)
```

#### World A

```{r}
fitA <- bartc(y, z, income + momage + dadage + events + siblings, data=worldA, estimand = c("att"), commonSup.rule = c("none", "sd", "chisq"), commonSup.cut  = c(NA_real_, 1, 0.05))

result <- data.frame()
result_bart <- data.frame()

A <- summary(fitA)
print(A)
temp <- A$estimates["estimate"]
bart.est.A <- temp$estimate
bart.sd.A = A$estimates["sd"]
#std.A <- est.A/sd(worldA$y)
#biasA <- a.ate/sd(worldA$y) - std.A

temp.result <- data.frame(World = "World A", SATE=a.ate, SATT=a.att, BART_ATT =bart.est.A, sd=bart.sd.A, Bias=biasA )

f.result <- data.frame(World = 'World A', SATT=a.att, PSM_ATT= cala.att.psm, BART_ATT= bart.est.A, Bias=biasA)

result_bart <- rbind(result_bart, temp.result)
result <- rbind(result, f.result)
```


#### World B

```{r}
fitB <- bartc(y, z, income + momage + dadage + events + siblings, data=worldB, estimand = c("att"), commonSup.rule = c("none", "sd", "chisq"), commonSup.cut  = c(NA_real_, 1, 0.05))

B <- summary(fitB)
print(B)
temp <- B$estimates["estimate"]
bart.est.B <- temp$estimate
bart.sd.B <- B$estimates["sd"]
#std.B <- est.B/sd(worldB$y)
#biasB <- b.ate/sd(worldA$y) - std.B

temp.result <- data.frame(World = "World B", SATE=b.ate, SATT=b.att, BART_ATT=bart.est.B, sd=bart.sd.B, Bias=biasB )

f.result <- data.frame(World = 'World B', SATT=b.att, PSM_ATT= calb.att.psm, BART_ATT= bart.est.B, Bias=biasB)

result_bart <- rbind(result_bart, temp.result)
result <- rbind(result, f.result)

```

#### World C

```{r}
fitC <- bartc(y, z, income + momage + dadage + events + siblings, data=worldB, estimand = c("att"), commonSup.rule = c("none", "sd", "chisq"), commonSup.cut  = c(NA_real_, 1, 0.05))

C <- summary(fitC)
print(C)
temp <- C$estimates["estimate"]
bart.est.C <- temp$estimate
bart.sd.C <- C$estimates["sd"]
#std.C <- est.C/sd(worldC$y)
#biasC <- c.ate/sd(worldC$y) - std.C

temp.result <- data.frame(World = "World C", SATE=c.ate, SATT=c.att, BART_ATT=bart.est.C, sd=bart.sd.C, Bias=biasC )

f.result <- data.frame(World = 'World C', SATT=c.att, PSM_ATT= calc.att.psm, BART_ATT= bart.est.C, Bias=biasC)

result_bart <- rbind(result_bart, temp.result)
result <- rbind(result, f.result)

```

## 5. Results

```{r}
print(result_psm)
```

```{r}
print(result_bart)
```

```{r}
print(result)
```
## 6. Assumption Discussion

To yield a valid causal estiamate using *PSM* the following assumptions need to be fullfilled.

  a. Ignorability :- This is neccesary to estimate the effect without Bias. THis assumption holds when all the confounders are measured.
  
  b. Overlap :- Having sufficient overlap is required to make causal inferences. If a model is fitted without complete overlap it extrapolates.
  
  c. Balance :- This assumption requires the distributions of the confoudners in the treatment and the control group to be close. If imbalance exists, bias creeeps in and we have to rely more on the correctness of the model.
  
  d. SUTVA :- No interaction between the individual children.
  
  e. Parametric Assumption :- The parametric form of the model is correct.
  
To yield a valid causal estiamate using *BART* the following assumptions need to be fullfilled.

  a. Structural Assumptions : - Weak Ignorability must hold (BART works when there is lack of overlap). 
  b. Parametric Assumptions must be satisfied.
  
BART constructs a counterfactual for each data point with a certainity interval, so that for those points which have empirical conterfactuals the certainity interval is small and those without the empirical counterfactual the interval gets bigger. Using the common support rule we can discard points which have high uncertainity. Hence even if there is lack of overlap it performs well.

## 7. Conclusion

Propensity Score Matching is usefull to estimate causal effect when the confounding covariates are know (throught research). Here the ignorability assumption must be strong as the inference is drawn using scores dervied from what we think the confounders are (forcing overlap)

Even if ignorability holds, imbalance and overlap could still be issues which let's us evaluate the adequacy of the propensity scores and the model used.

BART is usefull to estimate treatment effects when the confounders have lack of overlap. It incorporates the outcome for understanding what covariates are important common support.

It also provides a flexible fit to varying response surface and can work on weak ignorability assumptions.